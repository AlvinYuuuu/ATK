services:
  # Mem0 - Vector Database for AI Memory
  mem0:
    image: mem0/mem0-api-server:latest
    container_name: mem0-db
    ports:
      - "8080:8080"
    environment:
      - HOST=0.0.0.0
      - PORT=8080
      - LOG_LEVEL=${MEM0_LOG_LEVEL:-info}
      - API_KEY=${MEM0_API_KEY}
      - ENV=${MEM0_ENV:-development}
    volumes:
      - ./.docker/mem0:/app/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # Langfuse - LLM Observability Platform
  langfuse:
    image: langfuse/langfuse:latest
    container_name: langfuse-server
    ports:
      - "3000:3000"
    environment:
      - DATABASE_URL=postgresql://langfuse:langfuse@postgres:5432/langfuse
      - NEXTAUTH_SECRET=${NEXTAUTH_SECRET:-your-secret-key-here}
      - NEXTAUTH_URL=${NEXTAUTH_URL:-http://localhost:3000}
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=langfuse
      - POSTGRES_USER=langfuse
      - POSTGRES_PASSWORD=langfuse
      - LANGFUSE_PUBLIC_KEY=${LANGFUSE_PUBLIC_KEY}
      - LANGFUSE_SECRET_KEY=${LANGFUSE_SECRET_KEY}
      - LANGFUSE_HOST=${LANGFUSE_HOST:-http://localhost:3000}
      - ENV=${ENV:-development}
      - DEBUG=${DEBUG:-true}
    depends_on:
      postgres:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # PostgreSQL Database for Langfuse
  postgres:
    image: postgres:15-alpine
    container_name: langfuse-postgres
    environment:
      - POSTGRES_DB=${POSTGRES_DB:-langfuse}
      - POSTGRES_USER=${POSTGRES_USER:-langfuse}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-langfuse}
      - POSTGRES_INITDB_ARGS=--encoding=UTF-8
    volumes:
      - ./.docker/postgres:/var/lib/postgresql/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U langfuse -d langfuse"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis for Langfuse caching (optional but recommended)
  redis:
    image: redis:7-alpine
    container_name: langfuse-redis
    ports:
      - "6379:6379"
    environment:
      - REDIS_PASSWORD=${REDIS_PASSWORD:-}
      - REDIS_MAXMEMORY=${REDIS_MAXMEMORY:-256mb}
      - REDIS_MAXMEMORY_POLICY=${REDIS_MAXMEMORY_POLICY:-allkeys-lru}
    volumes:
      - ./.docker/redis:/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3

# volumes:
  # Volumes are now mounted to .docker directory in project
  # This allows for easier data access and backup

networks:
  default:
    name: ai-consultant-network 